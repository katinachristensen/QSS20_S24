{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 4: APIs, SQL, and supervised machine learning\n",
    "\n",
    "**Total points (without extra credit)**: 48 \n",
    "\n",
    "\n",
    "## Resources from class\n",
    "\n",
    "### APIs\n",
    "- [Lecture slides](https://docs.google.com/presentation/d/1eblPOhpOL1HDFk3XOh3KvcrFceJ4pwZNUU_fvU8i7uo/edit#slide=id.p)\n",
    "- [Activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/06_apis_solutions.ipynb)\n",
    "\n",
    "\n",
    "### Supervised ML\n",
    "- [Lecture slides 1](https://docs.google.com/presentation/d/1V6X9aYkYLvyh3Ea0ZSn3qkttqKz7OOPkfvbqYybMi5Q/edit#slide=id.p)\n",
    "- [Lecture slides 2](https://docs.google.com/presentation/d/13xJTI_GZ2HZYI9OSmezwLUXXFxIrjwHXKz50QUjBF0w/edit)\n",
    "- [Intro activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/08_ML_intro_activity_solutions.ipynb)\n",
    "- [Part II activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/08_ML_optimization_activity_solutions.ipynb)\n",
    "- [DataCamp course](https://app.datacamp.com/learn/courses/supervised-learning-with-scikit-learn)\n",
    "\n",
    "### SQL\n",
    "- [Lecture slides](https://docs.google.com/presentation/d/1HHgrkFtuhGIaPNMd1EOiM-8VtgnF0cwjMcmah8oWmWA/edit?usp=sharing)\n",
    "- [Example code](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/09_SQL_examplecode.ipynb)\n",
    "- [Activity solutions](https://github.com/herbertfreeze/QSS_Public/blob/main/activities/solutions/09_SQL_activity_solutions.ipynb)\n",
    "- [DataCamp course](https://app.datacamp.com/learn/courses/introduction-to-sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep work: change SQL dataset\n",
    "\n",
    "- Place it in [the same credentials yaml file on GitHub that contains the SQL database access information](https://github.com/herbertfreeze/QSS_public/blob/main/activities/09_db_cred.yaml) (password, host, etc.) \n",
    "    - Name the combined credentials file something appropriate (feel free to get creative)\n",
    "    - Change the database name from `sentencing` to `math_gencompare`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note you need to install some of the packages imported below (see the comments).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import plotnine \n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## note: you may need to install these using !pip install\n",
    "#!pip install census\n",
    "#!pip install us\n",
    "import census\n",
    "from census import Census\n",
    "import us\n",
    "from us import states\n",
    "import mysql.connector\n",
    "\n",
    "## sklearn imports\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## print mult things\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "def load_creds(path: str):\n",
    "    with open(path, 'r') as stream:\n",
    "        try:\n",
    "            creds = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return(creds)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a wrapper function to pull data from the NAEP API (12 points)\n",
    "\n",
    "In the class activity on APIs (see link above), we practiced pulling from the API for the National Assessment of Educational Progress (NAEP), \"America's report card\" of test scores. We pulled a small amount of data at the national level (writing scores by gender) using a query where the parameters were hardcoded.\n",
    "    \n",
    "In this problem, we'll practice pulling a larger set of data and writing a wrapper function.\n",
    "    \n",
    "As a reminder, the documentation is here: https://www.nationsreportcard.gov/api_documentation.aspx\n",
    "\n",
    "The base link is: https://www.nationsreportcard.gov/Dataservice/GetAdhocData.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Write a query to pull 8th-grade mathematics scores in 2015 from the state of California (CA) by gender (1 point)\n",
    "\n",
    "- Subject: mathematics \n",
    "- Subscale: MRPCM composite scale \n",
    "- Grade: 8\n",
    "- Year: 2015\n",
    "- grouping variable: GENDER \n",
    "- Jurisdiction: CA \n",
    "- stattype = MN (for mean)\n",
    "\n",
    "Print the output in dataframe format and briefly interpret; what do scores look like between the genders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.nationsreportcard.gov/Dataservice/GetAdhocData.aspx?type=data&subject=mathematics&grade=8&subscale=MRPCM&variable=GENDER&jurisdiction=CA&stattype=MN:MN&Year=2015'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 200,\n",
       " 'result': [{'year': 2015,\n",
       "   'sample': 'R3',\n",
       "   'yearSampleLabel': '2015',\n",
       "   'Cohort': 2,\n",
       "   'CohortLabel': 'Grade 8',\n",
       "   'stattype': 'MN:MN',\n",
       "   'subject': 'MAT',\n",
       "   'grade': 8,\n",
       "   'scale': 'MRPCM',\n",
       "   'jurisdiction': 'CA',\n",
       "   'jurisLabel': 'California',\n",
       "   'variable': 'GENDER',\n",
       "   'variableLabel': 'Gender',\n",
       "   'varValue': '1',\n",
       "   'varValueLabel': 'Male',\n",
       "   'value': 275.020976636682,\n",
       "   'isStatDisplayable': 1,\n",
       "   'errorFlag': 0},\n",
       "  {'year': 2015,\n",
       "   'sample': 'R3',\n",
       "   'yearSampleLabel': '2015',\n",
       "   'Cohort': 2,\n",
       "   'CohortLabel': 'Grade 8',\n",
       "   'stattype': 'MN:MN',\n",
       "   'subject': 'MAT',\n",
       "   'grade': 8,\n",
       "   'scale': 'MRPCM',\n",
       "   'jurisdiction': 'CA',\n",
       "   'jurisLabel': 'California',\n",
       "   'variable': 'GENDER',\n",
       "   'variableLabel': 'Gender',\n",
       "   'varValue': '2',\n",
       "   'varValueLabel': 'Female',\n",
       "   'value': 275.638637274477,\n",
       "   'isStatDisplayable': 1,\n",
       "   'errorFlag': 0}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sample</th>\n",
       "      <th>yearSampleLabel</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>CohortLabel</th>\n",
       "      <th>stattype</th>\n",
       "      <th>subject</th>\n",
       "      <th>grade</th>\n",
       "      <th>scale</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>jurisLabel</th>\n",
       "      <th>variable</th>\n",
       "      <th>variableLabel</th>\n",
       "      <th>varValue</th>\n",
       "      <th>varValueLabel</th>\n",
       "      <th>value</th>\n",
       "      <th>isStatDisplayable</th>\n",
       "      <th>errorFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>R3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>275.020977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>R3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>275.638637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year sample yearSampleLabel  Cohort CohortLabel stattype subject  grade  scale jurisdiction  jurisLabel variable variableLabel varValue varValueLabel       value  isStatDisplayable  errorFlag\n",
       "0  2015     R3            2015       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        1          Male  275.020977                  1          0\n",
       "1  2015     R3            2015       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        2        Female  275.638637                  1          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naep_query_1 = (\n",
    "# base link\n",
    "'https://www.nationsreportcard.gov/'\n",
    "'Dataservice/GetAdhocData.aspx?'\n",
    "#filters\n",
    "'type=data&subject=mathematics&grade=8&'\n",
    "'subscale=MRPCM&variable=GENDER&jurisdiction=CA&stattype=MN:MN&Year=2015')\n",
    "\n",
    "naep_query_1\n",
    "## use requests to call the api\n",
    "naep_resp = requests.get(naep_query_1)\n",
    "naep_resp\n",
    "print(type(naep_resp))\n",
    "\n",
    "## get the json contents of the response \n",
    "## here, we're assuming valid response\n",
    "naep_resp_j = naep_resp.json()\n",
    "naep_resp_j\n",
    "\n",
    "## with result, turn it into a dataframe\n",
    "naep_resp_d = pd.DataFrame(naep_resp_j['result'])\n",
    "naep_resp_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Write a query to pull 8th-grade mathematics scores in 2013, 2015, 2017, and 2019 from California by gender (1 point)\n",
    "\n",
    "Same as 1.1 but pull the years 2013, 2015, 2017, and 2019 (search documentation for how to combine) in one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sample</th>\n",
       "      <th>yearSampleLabel</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>CohortLabel</th>\n",
       "      <th>stattype</th>\n",
       "      <th>subject</th>\n",
       "      <th>grade</th>\n",
       "      <th>scale</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>jurisLabel</th>\n",
       "      <th>variable</th>\n",
       "      <th>variableLabel</th>\n",
       "      <th>varValue</th>\n",
       "      <th>varValueLabel</th>\n",
       "      <th>value</th>\n",
       "      <th>isStatDisplayable</th>\n",
       "      <th>errorFlag</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>R3</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>277.167171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>R3</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>274.597824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>R3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>275.020977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>R3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>275.638637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>R3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>276.608704</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>R3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>276.669430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>R3</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>274.511628</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>R3</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>Grade 8</td>\n",
       "      <td>MN:MN</td>\n",
       "      <td>MAT</td>\n",
       "      <td>8</td>\n",
       "      <td>MRPCM</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>276.721824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year sample yearSampleLabel  Cohort CohortLabel stattype subject  grade  scale jurisdiction  jurisLabel variable variableLabel varValue varValueLabel       value  isStatDisplayable  errorFlag  Year\n",
       "0  2013     R3            2013       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        1          Male  277.167171                  1          0  2013\n",
       "1  2013     R3            2013       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        2        Female  274.597824                  1          0  2013\n",
       "2  2015     R3            2015       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        1          Male  275.020977                  1          0  2015\n",
       "3  2015     R3            2015       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        2        Female  275.638637                  1          0  2015\n",
       "4  2017     R3            2017       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        1          Male  276.608704                  1          0  2017\n",
       "5  2017     R3            2017       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        2        Female  276.669430                  1          0  2017\n",
       "6  2019     R3            2019       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        1          Male  274.511628                  1          0  2019\n",
       "7  2019     R3            2019       2     Grade 8    MN:MN     MAT      8  MRPCM           CA  California   GENDER        Gender        2        Female  276.721824                  1          0  2019"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base URL and parameters\n",
    "base_url = 'https://www.nationsreportcard.gov/Dataservice/GetAdhocData.aspx?'\n",
    "parameters = {\n",
    "    'type': 'data',\n",
    "    'subject': 'mathematics',\n",
    "    'grade': 8,\n",
    "    'subscale': 'MRPCM',\n",
    "    'variable': 'GENDER',\n",
    "    'jurisdiction': 'CA',\n",
    "    'stattype': 'MN:MN'\n",
    "}\n",
    "\n",
    "# Years to retrieve\n",
    "years = [2013, 2015, 2017, 2019]\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each year and make a request\n",
    "for year in years:\n",
    "    # Update the year in parameters\n",
    "    parameters['Year'] = year\n",
    "    \n",
    "    # Create the query URL\n",
    "    query_url = base_url + '&'.join([f\"{key}={value}\" for key, value in parameters.items()])\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.get(query_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Assuming the structure of the data is known and extractable\n",
    "        # Here we assume the response includes 'Results' key with relevant data\n",
    "        results = data['result']\n",
    "        \n",
    "        # Add the year to the results\n",
    "        for result in results:\n",
    "            result['Year'] = year\n",
    "        \n",
    "        # Append the results to the all_data list\n",
    "        all_data.extend(results)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for year {year}: {response.status_code}\")\n",
    "\n",
    "# Create a DataFrame from all_data\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create a line plot to show variation in the scores across years (2 points)\n",
    "\n",
    "Using the results from 1.2, create a plot where the x axis has the year and the y axis is the math scores (`value` in dataframe), and there are separate lines/colors for male versus female students (`varValueLabel` in dataframe)\n",
    "\n",
    "Start the limits of the y axis minimum at 272 and add informative labels. Be sure your x-axis is ticked on odd years, because NAEP scores skip even years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Reproduce the queries from 1.1 and 1.2 using a user-defined function (4 points)\n",
    "\n",
    "Create a function, `construct_naep_query` that takes in two arguments:\n",
    "\n",
    "- year: this should be a list with all years (so if one year, single element list; if multiple years, list with those years)\n",
    "- place: this should be a string with the name of the state or jurisdiction to pull \n",
    "    \n",
    "Have the function return the query and make sure it's identical to the queries you wrote for 1.1 and 1.2 (can use assert or other checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_api_query(years: list,\n",
    "                   place: list,\n",
    "                   baseurl = 'https://www.nationsreportcard.gov/Dataservice/GetAdhocData.aspx?',\n",
    "                   query_part1 = 'data&subject=mathematics&grade=8',\n",
    "                   query_part3 = 'subscale=MRPCM&variable=GENDER&jurisdiction=CA&stattype=MN:MN'):\n",
    "                       \n",
    "    '''This function calls the NAEP API to get data on writing scores for the grade requested in 2011.\n",
    "    \n",
    "    Parameters:\n",
    "        baseurl (str): default URL for NAEP or similar API\n",
    "        query_part1 (str): first batch of arguments\n",
    "        grades (list of int): what grades to get data on\n",
    "        query_part3 (str): third batch of arguments\n",
    "    Returns:\n",
    "        DataFrame with the results'''\n",
    "    \n",
    "    dflist = []\n",
    "    \n",
    "    for year in years:\n",
    "        naep_query = baseurl + query_part1  + query_part3 + ('&Year=' + str(year)) + ('&jurisdiction=' + str(place))\n",
    "        naep_resp = requests.get(naep_query)\n",
    "        dflist.append(naep_resp)\n",
    "        \n",
    "        #if \"System.Exception\" in naep_resp.text:\n",
    "        #    print(f\"NAEP results not found for grade {str(grade)}, please try with grade in range of 1-12\")\n",
    "        #else:\n",
    "      #  try:\n",
    "           # naep_resp_df = pd.DataFrame(naep_resp.json()['result'])\n",
    "           # dflist.append(naep_resp_df)\n",
    "      #   except Exception as e:\n",
    "          #  print(\"Failed to get result from API for year {} due to error:\".format(str(year)))\n",
    "           # print(e)\n",
    "        \n",
    "    combined_result_df = pd.concat(dflist)\n",
    "    \n",
    "    return(combined_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'requests.models.Response'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m construct_api_query(years \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2015\u001b[39m], place \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 34\u001b[0m, in \u001b[0;36mconstruct_api_query\u001b[0;34m(years, place, baseurl, query_part1, query_part3)\u001b[0m\n\u001b[1;32m     22\u001b[0m     dflist\u001b[38;5;241m.\u001b[39mappend(naep_resp)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#if \"System.Exception\" in naep_resp.text:\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#    print(f\"NAEP results not found for grade {str(grade)}, please try with grade in range of 1-12\")\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[38;5;66;03m#  print(\"Failed to get result from API for year {} due to error:\".format(str(year)))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m        \u001b[38;5;66;03m# print(e)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m combined_result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dflist)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(combined_result_df)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    383\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m    384\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    385\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[1;32m    386\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[1;32m    387\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[1;32m    388\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[1;32m    389\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:446\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n\u001b[1;32m    447\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:487\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    483\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         )\n\u001b[0;32m--> 487\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    489\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'requests.models.Response'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "construct_api_query(years = [2015], place = 'CA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Write and execute user-defined function that takes in a query and returns a pandas dataframe with the content of the response (4 points)\n",
    "\n",
    "- Write a user-defined function (`process_naep_query`) that takes in the CA-specific NAEP query as a string, calls the API, and transforms the response into a pandas dataframe. Have the function return that pandas dataframe\n",
    "\n",
    "- Make sure the function is flexible enough to handle queries that return an error; for queries that return an error, have the function return the string \"Data not found; check your query\" (see [API part 1 solutions code](https://github.com/herbertfreeze/QSS_public/blob/main/activities/solutions/06_apis_solutions.ipynb) for an example of `try:`/`except:`)\n",
    "\n",
    "- Execute the function on the query that pulls 2013-2019 data (either from handwriting the query or the result in 1.4)\n",
    "\n",
    "- Print the resulting dataframe\n",
    "\n",
    "- Then execute the function on a query that pulls a state that doesn't exist (call this state ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore data using SQL queries (18 points)\n",
    "\n",
    "In the previous example, you worked with the data in a flat file and manipulated it using pandas. Here, we're going to practice running queries to do some calculations using SQL --- in the case of our data, this is a bit overkill since the data are small but it is practice for larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load database credentials and establish a connection (1 point)\n",
    "\n",
    "Load a credentials file that contains the credentials you'll need for this and the next problem:\n",
    "\n",
    "- The credentials for our class database\n",
    "- The credentials for the Census API (see instructions above)\n",
    "\n",
    "Note: to establish the SQL connection, you need to be on `eduroam` (near campus) or the Dartmouth's GlobalProtect `VPN`  ([installation instructions here](https://services.dartmouth.edu/TDClient/1806/Portal/KB/ArticleDet?ID=72395))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PATH TO YOUR CREDS FILE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m creds \u001b[38;5;241m=\u001b[39m load_creds(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH TO YOUR CREDS FILE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mload_creds\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_creds\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m             creds \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(stream)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PATH TO YOUR CREDS FILE'"
     ]
    }
   ],
   "source": [
    "creds = load_creds(\"PATH TO YOUR CREDS FILE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run a query to select all columns and the first 5 rows of the math_gencompare database to explore structure (2 points)\n",
    "\n",
    "Read the results in as a pandas dataframe and print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Find the (1) number of rows in the database, (2) number of distinct states,  (3) number of distinct years (3 points)\n",
    "\n",
    "Interpret the results - how do you think the data is structured in terms of states and years (eg long format where each state repeated; wide format)?\n",
    "\n",
    "**Hint**: rather than using count `(*)` for the latter two, think about the `distinct` command in combination with `count`: https://www.w3resource.com/mysql/aggregate-functions-and-grouping/aggregate-functions-and-grouping-count-with-distinct.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Construct a new variable, `is_male_higher` that takes the value of 1 if the math scores of males exceed that of females in that state and year (each row) (2 points)\n",
    "\n",
    "Read in the results, print the head, and find the mean across all rows (the percentage of state-years where male students have higher scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 group by year and find the percentage of states where male scores are higher than females (4 points)\n",
    "\n",
    "**A.** Write a query that (1) groups by year and (2) finds the percentage of states that have higher scores for males than females in this year \n",
    "\n",
    "**B.** Print the resulting dataframe and interpret the results \n",
    "\n",
    "**Hint:** To compare male and female scores, consider logical operators (e.g., `<`, `>`, `=`) and simple aggregation (e.g., `avg()` to get mean) or using a subquery to construct the indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 group by state and find the percentage of years where male scores higher than females\n",
    "\n",
    "**A.** Write a query that (1) groups by state and (2) finds the percentage of years that have higher scores for males than females in that state\n",
    "\n",
    "**B.** Plot the results ordering the states from males higher all 4 years to males higher none of the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Use a subquery to create an indicator and group by that indicator (6 points)\n",
    "\n",
    "The following states were the first 6 to expand the right to vote to women before the uniform federal expansion in 1920\n",
    "\n",
    "- Wyoming 1890\n",
    "- Colorado 1893\n",
    "- Utah 1896\n",
    "- Idaho 1896\n",
    "- Washington 1910\n",
    "- California 1911\n",
    "\n",
    "**A.** Create an indicator `is_early_voter` for whether a state is in that list or not; do so without typing the state names inside the string and instead collapsing the list of states we provide and using something like `format`. Hint on how to combine the state names while preserving the quotes around each: https://stackoverflow.com/questions/12007686/join-a-list-of-strings-in-python-and-wrap-each-string-in-quotation-marks \n",
    "\n",
    "**B.** Then, group by the `is_early_voter` indicator and `year` and find the percencentage of states in each group where males had higher scores than females \n",
    "\n",
    "**C.** Print the resulting dataframe and interpret. Does early expansion of voting seem to be correlated with girls scoring better on the math tests a century later?\n",
    "\n",
    "**Hint:** in order to group by the indicator in step b, you may need to use a subquery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of states we provide\n",
    "list_suffrage = [\"Wyoming\", \"Colorado\", \"Utah\", \"Idaho\", \"Washington\", \n",
    "                \"California\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore variation in math score disparities and trends (18 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Read in the `acs_wmath.pkl` file (csv is backup) (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create a visualization where one axis is the state; the other axis is the male 2013 math scores - the female 2013 math scores (gender disparity) (2 points)\n",
    "\n",
    "\n",
    "You have free rein over additional details but make sure it is informative over what direction of disparity positive versus negative values mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Examine gender disparity in relation to household income (6 points)\n",
    "\n",
    "**A.** Construct an indicator variable for the state having better performance of males in 2013 than females\n",
    "\n",
    "**B.** First plot a scatterplot (or seaborn regplot) of estimated median household income from the acs data (we provide varname below) vs `math_male_2013`. Then do a second smoothed scatterplot for median household income vs `math_female_2013`.\n",
    "\n",
    "**C.** \n",
    "Then use the `np.corrcoef` command (three separate times) to examine the bivariate correlation of\n",
    "- male performance\n",
    "- female performance\n",
    "- the indicator variable from **A** \n",
    "\n",
    "with median household income (`acspredict_median_household_income_in_the_past_12_months__in_2018_inflation-adjusted_dollars_estimatemedian household income in the past 12 months in 2018 inflationadjusted dollars`)\n",
    "\n",
    "Documentation: https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "\n",
    "**D.** Interpret the correlations - in states with higher median household income (MHI), do \n",
    "   - boys tend to perform better than boys in states with lower MHI?\n",
    "   - girls tend to perform better than girls in states with lower MHI?\n",
    "   - boys tend to outperform girls more than they do in states with lower MHI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Predicting disparities (10 points)\n",
    "\n",
    "**A.** Read in the raw `acs_wmath` data again (this loses the variables you created above)\n",
    "\n",
    "**B.** Construct a binary indicator variable for male score > female score  for each year - for full credit, do so without repeating the difference code for each of the four years: name these according to following convention: `outcome_male_higher_female_year` where year is 2013, 2015, 2017, or 2019 (e.g., 2013: `outcome_male_higher_female_2013`). After this, remove the raw math scores as columns in the data (so filter out any column with the word math)\n",
    "\n",
    "**C.** Melt the data (`acs_wmath`) to long where instead of wide years, years are repeated within state; the ACS vars will also be repeated since we only pulled one year. In other words, reshape the data from \"wide format\", where each state is a row and we have separate columns for each year, to \"long format\", where states are repeated four times: once for each year in the data (2013, 2015, 2017, 2019). With 50 states, your final shape should be (200,84).\n",
    "- See: https://pandas.pydata.org/docs/reference/api/pandas.melt.html\n",
    "\n",
    "**D.** Split into train-test split at state level (so all years in same state -> either all in train or all test). Randomize 35 states to train; 15 states in test. \n",
    "\n",
    "**E.** Normalize the features to mean 0, variance 1 and estimate a decision tree with a max depth of 5. Your covariates should have the term 'acspredict' in it.\n",
    "\n",
    "- **Hint:** The ML literature recommends using the training set scaler to transform the test set, rather than using a unique scaler to initialize each one. The reasons are discussed here: https://stats.stackexchange.com/questions/495357/why-do-we-normalize-test-data-on-the-parameters-of-the-training-data\n",
    "\n",
    "**F.** Interpret the feature importances\n",
    "\n",
    "**G.** Evaluate the precision and recall of that model in the test set states without using the `score`, `precision`, or `recall` functions in sklearn. Briefly interpret: compared to our class example (a high-dimensional feature matrix of yelp reviews with ~15000 observations), why do you think our models perform worse for this set of data/predictors?\n",
    "\n",
    "**Additional resources:** \n",
    "\n",
    "- Feature normalization: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "- Definition of precision and recall: https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. your code here to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. your code here to construct binary indicators for male higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. your code here to melt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. your code here for train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E. your code here to normalize features and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F. your code here to interpret feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G. your code here to evaluate model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
